# ü§ñ Integra√ß√£o de Aplica√ß√£o Python com Ollama

Projeto de aprendizado focado em integrar aplica√ß√µes Python com modelos de IA locais usando Ollama.

## Autor

**Caio** - Desenvolvedor aprendendo integra√ß√£o de IA

## Objetivo

Explorar na pr√°tica a integra√ß√£o entre Python e Ollama para executar modelos de linguagem localmente, sem depend√™ncia de servi√ßos externos ou custos de API.

### O que este projeto ensina:
- Consumir a API do Ollama
- Estruturar prompts eficientes
- Tratar e manipular respostas de IA
- Desenvolver aplica√ß√µes independentes

## Aprendizados

- Comunica√ß√£o Python ‚Üî Ollama via API
- Boas pr√°ticas em engenharia de prompts
- Estrutura√ß√£o de respostas para diferentes casos de uso
- Fundamentos de integra√ß√£o de IA em projetos pessoais

## Pr√≥ximos Passos

- [ ] Criar exemplos avan√ßados de prompts
- [ ] Integrar com Flask ou FastAPI
- [ ] Explorar diferentes modelos do Ollama
- [ ] Documentar casos de uso pr√°ticos

## Como Usar

```bash
# Clone o reposit√≥rio
git clone [seu-repositorio]

# Instale as depend√™ncias
pip install -r requirements.txt

# Execute a aplica√ß√£o
python main.py
```

## Requisitos

- Python 3.8+
- Ollama instalado localmente
- Bibliotecas listadas em `requirements.txt`

---
**Dica**: Certifique-se de ter o Ollama rodando antes de executar a aplica√ß√£o.